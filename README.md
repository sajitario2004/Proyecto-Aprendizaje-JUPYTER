# üß† Configuraci√≥n de Entorno para IA en WINDOWS (Miniconda + NVIDIA RTX 50 Series)

Este repositorio documenta la configuraci√≥n del entorno de desarrollo y los scripts base para proyectos de Deep Learning y Data Science en Windows.

**Estado del Hardware:** Configuraci√≥n optimizada para trabajar con CPU y preparada para la transici√≥n a GPUs de √∫ltima generaci√≥n (NVIDIA RTX Serie 50 - Arquitectura Blackwell).

---

## üìã Requisitos Previos

Antes de ejecutar los comandos, aseg√∫rate de tener instalado:

1.  **[Miniconda (Windows 64-bit)](https://docs.conda.io/en/latest/miniconda.html):** Gesti√≥n eficiente de entornos.
2.  **[Visual Studio Code](https://code.visualstudio.com/):** Editor de c√≥digo recomendado.
3.  **Drivers NVIDIA:** √öltima versi√≥n (Game Ready o Studio) desde GeForce Experience.

---

## üõ†Ô∏è Gu√≠a de Instalaci√≥n (Paso a Paso)

Todos los comandos deben ejecutarse en **Anaconda Prompt (Miniconda3)**.

### 1. Creaci√≥n del Entorno Virtual
Se recomienda utilizar un disco secundario (ej. `D:`) para almacenar las librer√≠as y modelos pesados.

```bash
# 1. Crear el entorno en la carpeta del proyecto (D:\NvidiaIA)
# Confirmar con 'y' cuando se solicite.
conda create --prefix "D:\NvidiaIA" python=3.10

# 2. Activar el entorno (Imprescindible antes de instalar nada)
conda activate "D:\NvidiaIA"
2. Instalaci√≥n de Librer√≠as (Pip Install)
Instalamos el stack cient√≠fico b√°sico.

Nota: Este comando instala la versi√≥n actual. Si tu GPU es muy nueva (ej. RTX 5080) y PyTorch a√∫n no ha lanzado el soporte oficial estable para Windows, estas librer√≠as funcionar√°n autom√°ticamente en modo CPU sin errores.

Bash

pip install torch torchvision torchaudio numpy pandas matplotlib jupyterlab notebook
3. Configuraci√≥n en Visual Studio Code
Abrir VS Code y abrir la carpeta D:\NvidiaIA.

Instalar extensiones: Python y Jupyter.

Crear un archivo nuevo: main.ipynb.

Seleccionar Kernel: Arriba a la derecha, clic en "Select Kernel" -> "Python Environments" -> Seleccionar la ruta D:\NvidiaIA\python.exe.

üíª C√≥digo Universal de Inicializaci√≥n
Copia y pega este bloque al principio de tus notebooks (.ipynb). Este script es h√≠brido: detecta si la GPU es compatible y funciona; si hay errores de drivers o incompatibilidad (com√∫n en lanzamientos recientes como la serie 50), cambia autom√°ticamente a CPU para que puedas seguir trabajando.

Python

import torch
import sys

def get_device_info():
    """
    Configura el dispositivo de c√≥mputo.
    Maneja excepciones espec√≠ficas para GPUs nuevas (Blackwell/Hopper) 
    que a√∫n no tienen kernel image en la versi√≥n estable de PyTorch.
    """
    device_type = "cpu"
    status_msg = "‚ö†Ô∏è MODO CPU (GPU no detectada o drivers incompatibles)"
    
    try:
        # Verificamos si CUDA es visible
        if torch.cuda.is_available():
            # Intentamos una operaci√≥n real en memoria para confirmar compatibilidad
            # Esto fallar√° controladamente si la arquitectura (sm_120) no est√° soportada a√∫n
            dummy = torch.zeros(1).to("cuda")
            
            # Si pasa la prueba anterior, activamos GPU
            device_type = "cuda"
            gpu_name = torch.cuda.get_device_name(0)
            status_msg = f"‚úÖ MODO TURBO ACTIVO: {gpu_name}"
            
    except RuntimeError as e:
        # Captura errores como 'no kernel image is available'
        status_msg = f"‚ö†Ô∏è MODO CPU (GPU detectada pero requiere actualizaci√≥n de PyTorch): {e}"
    except Exception as e:
        status_msg = f"‚ö†Ô∏è MODO CPU (Error general): {e}"
    
    return torch.device(device_type), status_msg

# --- CONFIGURACI√ìN GLOBAL ---
DEVICE, MSG = get_device_info()

print("="*60)
print(f"üõ†Ô∏è  Sistema Operativo: {sys.platform}")
print(f"üî• Versi√≥n de PyTorch: {torch.__version__}")
print(f"üéØ Estado del Dispositivo: {MSG}")
print("="*60)

# Ejemplo de prueba (se ejecutar√° donde diga DEVICE)
x = torch.rand(5, 3).to(DEVICE)
print(f"\nTensor de prueba creado exitosamente en: {x.device}")
‚ö†Ô∏è Nota para Usuarios de RTX Serie 50 (Blackwell)
Si tienes una RTX 5080 / 5090, es normal recibir el error:

RuntimeError: CUDA error: no kernel image is available

Esto ocurre porque la arquitectura de la tarjeta (sm_120) es m√°s nueva que la versi√≥n estable de PyTorch en Windows.

Soluci√≥n:

Usa el modo CPU (el c√≥digo de arriba lo hace autom√°tico).

Espera a la actualizaci√≥n oficial de PyTorch.

Peri√≥dicamente, intenta actualizar a la versi√≥n "Nightly" (experimental) con este comando en la terminal:

Bash

# Solo ejecutar si se necesita soporte inmediato para GPU nueva
pip install --pre --upgrade torch torchvision --index-url [https://download.pytorch.org/whl/nightly/cu124](https://download.pytorch.org/whl/nightly/cu124)
```
# üß† Configuraci√≥n de Entorno para IA UBUNTU (Miniconda + NVIDIA RTX 50 Series) [Ubuntu]

Este repositorio documenta la configuraci√≥n del entorno de desarrollo y los scripts base para proyectos de Deep Learning y Data Science en **Ubuntu Linux**.

**Estado del Hardware:** Configuraci√≥n optimizada para trabajar con CPU y preparada para la transici√≥n a GPUs de √∫ltima generaci√≥n (NVIDIA RTX Serie 50 - Arquitectura Blackwell).

---

## üìã Requisitos Previos

Antes de ejecutar los comandos, aseg√∫rate de tener instalado:

1.  **[Miniconda (Linux 64-bit)](https://docs.conda.io/en/latest/miniconda.html#linux-installers):** Gesti√≥n eficiente de entornos.
2.  **[Visual Studio Code](https://code.visualstudio.com/):** Editor de c√≥digo recomendado (`sudo snap install code`).
3.  **Drivers NVIDIA:** Drivers propietarios instalados (v√≠a "Software & Updates" > "Additional Drivers" o l√≠nea de comandos).

---

## üõ†Ô∏è Gu√≠a de Instalaci√≥n (Paso a Paso)

Todos los comandos deben ejecutarse en la **Terminal**.

### 1. Creaci√≥n del Entorno Virtual
Crearemos el entorno en una carpeta local (ej. en tu `home`) para tener f√°cil acceso.

```bash
# 1. Crear el entorno en la carpeta ~/NvidiaIA
# Confirmar con 'y' cuando se solicite.
conda create --prefix ~/NvidiaIA python=3.10

# 2. Activar el entorno (Imprescindible antes de instalar nada)
conda activate ~/NvidiaIA
2. Instalaci√≥n de Librer√≠as (Pip Install)
Instalamos el stack cient√≠fico b√°sico.

Nota: Este comando instala la versi√≥n actual. Si tu GPU es muy nueva (ej. RTX 5080) y PyTorch a√∫n no ha lanzado el soporte oficial estable, estas librer√≠as funcionar√°n autom√°ticamente en modo CPU.

Bash

python3 -m pip install torch torchvision torchaudio numpy pandas matplotlib jupyterlab notebook
3. Configuraci√≥n en Visual Studio Code
Abrir VS Code y abrir la carpeta ~/NvidiaIA (o donde tengas tu c√≥digo).

Instalar extensiones: Python y Jupyter.

Crear un archivo nuevo: main.ipynb.

Seleccionar Kernel:

Clic en "Select Kernel" (arriba a la derecha).

Seleccionar "Python Environments".

Buscar la ruta: ~/NvidiaIA/bin/python (Importante: en Linux el ejecutable est√° dentro de la carpeta bin).

üíª C√≥digo Universal de Inicializaci√≥n
Copia y pega este bloque al principio de tus notebooks (.ipynb). Este script es h√≠brido: detecta si la GPU es compatible y funciona; si hay errores de drivers o incompatibilidad, cambia autom√°ticamente a CPU.

Python

import torch
import sys

def get_device_info():
    """
    Configura el dispositivo de c√≥mputo.
    Maneja excepciones espec√≠ficas para GPUs nuevas (Blackwell/Hopper) 
    que a√∫n no tienen kernel image en la versi√≥n estable de PyTorch.
    """
    device_type = "cpu"
    status_msg = "‚ö†Ô∏è MODO CPU (GPU no detectada o drivers incompatibles)"
    
    try:
        # Verificamos si CUDA es visible
        if torch.cuda.is_available():
            # Intentamos una operaci√≥n real en memoria para confirmar compatibilidad
            # Esto fallar√° controladamente si la arquitectura (sm_120) no est√° soportada a√∫n
            dummy = torch.zeros(1).to("cuda")
            
            # Si pasa la prueba anterior, activamos GPU
            device_type = "cuda"
            gpu_name = torch.cuda.get_device_name(0)
            status_msg = f"‚úÖ MODO TURBO ACTIVO: {gpu_name}"
            
    except RuntimeError as e:
        # Captura errores como 'no kernel image is available'
        status_msg = f"‚ö†Ô∏è MODO CPU (GPU detectada pero requiere actualizaci√≥n de PyTorch): {e}"
    except Exception as e:
        status_msg = f"‚ö†Ô∏è MODO CPU (Error general): {e}"
    
    return torch.device(device_type), status_msg

# --- CONFIGURACI√ìN GLOBAL ---
DEVICE, MSG = get_device_info()

print("="*60)
print(f"üõ†Ô∏è  Sistema Operativo: {sys.platform}")
print(f"üî• Versi√≥n de PyTorch: {torch.__version__}")
print(f"üéØ Estado del Dispositivo: {MSG}")
print("="*60)

# Ejemplo de prueba (se ejecutar√° donde diga DEVICE)
x = torch.rand(5, 3).to(DEVICE)
print(f"\nTensor de prueba creado exitosamente en: {x.device}")
‚ö†Ô∏è Nota para Usuarios de RTX Serie 50 (Blackwell)
Si tienes una RTX 5080 / 5090, es normal recibir el error RuntimeError: CUDA error: no kernel image is available si usas la versi√≥n estable de PyTorch.

Soluci√≥n:

Usa el modo CPU temporalmente (el c√≥digo de arriba lo gestiona solo).

Si necesitas forzar el uso de GPU antes del soporte oficial, prueba la versi√≥n Nightly:

Bash

# Solo ejecutar si se necesita soporte inmediato (Experimental)
pip install --pre --upgrade torch torchvision --index-url [https://download.pytorch.org/whl/nightly/cu124](https://download.pytorch.org/whl/nightly/cu124)
```
---

## üìö Roadmap de Especializaci√≥n en IA

Este plan de estudios consta de **36 temas** dise√±ados para avanzar desde los fundamentos matem√°ticos hasta la IA Generativa moderna, aprovechando la aceleraci√≥n por GPU.

### üêç M√ìDULO 1: Fundamentos de Python Cient√≠fico
*La base del manejo de datos antes de entrar en redes neuronales.*

- [ ] **01. NumPy I:** Arrays, dimensiones (shapes) y tipos de datos.
- [ ] **02. NumPy II:** Operaciones matem√°ticas vectorizadas y Broadcasting.
- [ ] **03. Pandas I:** DataFrames, lectura de archivos (CSV/Excel) y exploraci√≥n.
- [ ] **04. Pandas II:** Limpieza de datos, manejo de nulos y filtrado avanzado.
- [ ] **05. Visualizaci√≥n I:** Gr√°ficos est√°ticos con Matplotlib (l√≠neas, dispersi√≥n).
- [ ] **06. Preprocesamiento:** Normalizaci√≥n, estandarizaci√≥n y One-Hot Encoding.

### üìê M√ìDULO 2: Machine Learning Cl√°sico
*Entendiendo c√≥mo aprenden las m√°quinas (algoritmos tradicionales).*

- [ ] **07. Conceptos Clave:** Supervisado vs No Supervisado, Overfitting.
- [ ] **08. Regresi√≥n Lineal:** Predicci√≥n num√©rica y concepto de "Error".
- [ ] **09. Regresi√≥n Log√≠stica:** Clasificaci√≥n binaria y probabilidad.
- [ ] **10. √Årboles de Decisi√≥n:** Reglas de decisi√≥n interpretables.
- [ ] **11. M√©tricas de Evaluaci√≥n:** Accuracy, Precision, Recall, Matriz de Confusi√≥n.
- [ ] **12. Divisi√≥n de Datos:** Train, Validation y Test sets.

### üî• M√ìDULO 3: Deep Learning & PyTorch
*El n√∫cleo del aprendizaje profundo y uso de GPU.*

- [ ] **13. Tensores en PyTorch:** Diferencias con NumPy y uso de CUDA.
- [ ] **14. El Perceptr√≥n:** La neurona artificial y operaciones matriciales.
- [ ] **15. Redes Densas (MLP):** Capas ocultas y funciones de activaci√≥n (ReLU).
- [ ] **16. Funciones de P√©rdida:** MSE y CrossEntropy.
- [ ] **17. Optimizadores:** Descenso del gradiente, SGD y Adam.
- [ ] **18. El Training Loop:** Epochs, Batches y monitoreo de p√©rdida.

### üëÅÔ∏è M√ìDULO 4: Visi√≥n Artificial (Computer Vision)
*Ense√±ando a la m√°quina a "ver" e interpretar im√°genes.*

- [ ] **19. Convoluciones:** Filtros, Kernels y Mapas de caracter√≠sticas.
- [ ] **20. Pooling y Flattening:** Reducci√≥n de dimensionalidad.
- [ ] **21. Arquitectura CNN:** Construcci√≥n de redes convolucionales completas.
- [ ] **22. Data Augmentation:** Rotaciones y transformaciones para mejorar el dataset.
- [ ] **23. Transfer Learning:** Uso de modelos pre-entrenados (ResNet, VGG).
- [ ] **24. Persistencia:** Guardado (`.pth`) y carga de modelos (Checkpoints).

### üí¨ M√ìDULO 5: Procesamiento de Lenguaje Natural (NLP)
*Ense√±ando a la m√°quina a "leer" y entender texto.*

- [ ] **25. Preprocesamiento NLP:** Tokenizaci√≥n, limpieza y vocabulario.
- [ ] **26. Embeddings:** Representaci√≥n vectorial de palabras (Word2Vec).
- [ ] **27. Redes Recurrentes (RNNs):** Secuencias y memoria temporal.
- [ ] **28. LSTMs y GRUs:** Memoria a largo plazo y puertas l√≥gicas.
- [ ] **29. Mecanismo de Atenci√≥n:** La base de los modelos modernos.
- [ ] **30. Transformers:** Arquitectura Encoder-Decoder.

### ‚ú® M√ìDULO 6: IA Generativa y Avanzada
*Estado del arte: LLMs, Difusi√≥n y aplicaciones reales.*

- [ ] **31. Modelos BERT:** Entendimiento bidireccional del lenguaje.
- [ ] **32. Modelos GPT:** Generaci√≥n de texto autorregresiva.
- [ ] **33. Fine-Tuning:** Ajuste de LLMs (LoRA/PEFT) a datos propios.
- [ ] **34. Stable Diffusion:** Generaci√≥n de im√°genes a partir de texto.
- [ ] **35. RAG (Retrieval Augmented Generation):** Chat con documentos privados.
- [ ] **36. Despliegue (Deploy):** Creaci√≥n de demos web con Gradio/Streamlit.

---
